{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(ml_pipeline, X, y, n=5, k=10, score='accuracy'):\n",
    "    \"\"\"Perform N repeated K-fold cross-validation\n",
    "\n",
    "    Keyword arguments:\n",
    "    ml_pipeline -- Intance of scikit-learn's Pipeline\n",
    "    X -- Data to perform cross-validation\n",
    "    y -- Labels of the data\n",
    "    n -- Amount of times cross-validation is repeated (default is 5)\n",
    "    k -- Amount of folds that the data is splitted to perform \n",
    "         cross-validation (default is 10)\n",
    "    score -- Scoring type as a string for scikit-learn's \n",
    "             cross_val_score method (default is accuracy)\n",
    "    \n",
    "    Return:\n",
    "    Two element numpy array where first value is mean of cross-validation scores\n",
    "    and second is standard deviation of cross-validation scores.\n",
    "    \"\"\"\n",
    "    cv = RepeatedStratifiedKFold(n_splits = n, \n",
    "                                 n_repeats = k, \n",
    "                                 random_state = 1)\n",
    "    n_scores = cross_val_score(ml_pipeline, X, y, \n",
    "                               scoring = score, cv = cv, \n",
    "                               n_jobs = -1)\n",
    "    \n",
    "    return(np.array([np.mean(n_scores), np.std(n_scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lablesToBinary(multi_labels):\n",
    "    \"\"\"Transform multi-class labels of NPF data to binary labels\n",
    "\n",
    "    Keyword arguments:\n",
    "    multi_labels -- Labels to transform as pandas.Series\n",
    "    \n",
    "    Return:\n",
    "    Equal size pandas.Series containing binary labels\n",
    "    \"\"\"\n",
    "    return multi_labels.apply(lambda x: \"nonevent\" if x == \"nonevent\" else \"event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y, y_pred):\n",
    "    \"\"\"Compute accuracy score of the model\n",
    "\n",
    "    Keyword arguments:\n",
    "    y -- Real labels\n",
    "    y_pred -- Predicted labels\n",
    "    \n",
    "    Return:\n",
    "    Accuracy score as float number\n",
    "    \"\"\"\n",
    "    return np.mean(y == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_score(true_labels, pred_p):\n",
    "    \"\"\"Compute perplexity score of the model\n",
    "\n",
    "    Keyword arguments:\n",
    "    true_labels -- Real labels\n",
    "    pred_p -- Predicted probabilities of the model\n",
    "    \n",
    "    Return:\n",
    "    Perplexity score as float number\n",
    "    \"\"\"\n",
    "    cond_result = []\n",
    "\n",
    "    for i in range(0, true_labels.size):\n",
    "        if true_labels[i] == \"nonevent\":\n",
    "            cond_result.append(1 - pred_p[i])\n",
    "        else:\n",
    "            cond_result.append(pred_p[i])\n",
    "\n",
    "    return np.exp( -np.mean( np.log( np.array(cond_result) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_npf(classifier, X_tr, y, X_te):\n",
    "    \"\"\"Train ML model and predict test data\n",
    "\n",
    "    Keyword arguments:\n",
    "    classifier -- Intance of scikit-learn Pipeline\n",
    "    X_tr -- Training data\n",
    "    y -- Labels of the training data\n",
    "    X_te -- Test data\n",
    "    \n",
    "    Return:\n",
    "    Pandas.DataFrame containing predicted classes and their probabilities\n",
    "    \"\"\"\n",
    "    classifier.fit(X_tr, y)\n",
    "\n",
    "    classes = pd.Series(classifier.predict(X_te))\n",
    "    p = pd.DataFrame(classifier.predict_proba(X_te))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, classes.size):\n",
    "        label = classes[i]\n",
    "        p_value = p.loc[i, label]\n",
    "        results.append([label, p_value])\n",
    "\n",
    "    answers = pd.DataFrame(results, columns=['class4', 'p'])\n",
    "    answers['class4'] = mapping_class4[answers['class4']]\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/npf_train.csv', index_col='id')\n",
    "df.drop(['date', 'partlybad'], axis=1, inplace=True)\n",
    "\n",
    "class2 = df['class4'].copy()\n",
    "class2[class2 != 'nonevent'] = 'event'\n",
    "df['class2'] = class2\n",
    "\n",
    "df['class4'], mapping_class4 = df['class4'].astype('category').factorize()\n",
    "df['class2'], mapping_class2 = df['class2'].astype('category').factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/npf_test.csv', index_col='id')\n",
    "test_data = df_test.drop(['date', 'partlybad', 'class4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.drop(['class4', 'class2'], axis=1)\n",
    "\n",
    "scaled = StandardScaler().fit_transform(pd.concat([train_data, test_data]))\n",
    "\n",
    "X_train = pd.DataFrame(scaled[0:430], columns=train_data.columns)\n",
    "X_test = pd.DataFrame(scaled[430:], columns=train_data.columns)\n",
    "\n",
    "y_class2 = df['class2']\n",
    "y_class4 = df['class4']\n",
    "\n",
    "y_test, mapping_test = df_test['class4'].astype('category').factorize()\n",
    "y_test = mapping_test[y_test]\n",
    "\n",
    "y_test_binary = lablesToBinary(pd.Series(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = ('kbestmutual', SelectKBest(mutual_info_classif, k=90))\n",
    "selecttree = ('selecttree', SelectFromModel(ExtraTreesClassifier(n_estimators=70)))\n",
    "\n",
    "p = 0.7\n",
    "var = p * (1 - p)\n",
    "\n",
    "pca = ('pca', PCA())\n",
    "sel = ('sel', VarianceThreshold(threshold=var))\n",
    "\n",
    "gaussian = ('model', GaussianProcessClassifier(1.0 * RBF(1.0)))\n",
    "logistic = ('model', LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = Pipeline([kbest, gaussian])\n",
    "multi = Pipeline([selecttree, logistic])\n",
    "\n",
    "main = Pipeline([gaussian])\n",
    "\n",
    "main_alter1 = Pipeline([pca, gaussian])\n",
    "main_alter2 = Pipeline([sel, gaussian])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = predict_npf(main, X_train, y_class4, X_test)\n",
    "\n",
    "acc_binary = accuracy_score(y_test_binary, lablesToBinary(pred_df['class4']))\n",
    "acc_multi = accuracy_score(y_test, pred_df['class4'])\n",
    "perp = perplexity_score(y_test, pred_df['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787564766839379\n",
      "0.694300518134715\n",
      "3.526965890904833\n"
     ]
    }
   ],
   "source": [
    "print(acc_binary)\n",
    "print(acc_multi)\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('../results/answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
